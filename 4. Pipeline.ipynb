{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run pipelines to model the data\n",
    "In the first step, we cleaned our data from \"raw_data\" and stored the output in \"data\". Now it's time to get them into a format that is more representative of the final relational database and more easily read by them.\n",
    "\n",
    "I'm using Spark for the data transformation, more precisely PySpark. It's a good tool for dealing with large amounts of data in parallel, and supports the final output format of my choice: Parquet. The result of this pipeline will be stored in the \"output\" folder.\n",
    "\n",
    "As discussed in the previous step, we'll need to create five tables in total. I've split out each table into its own notebook. In each notebook, we'll explore how to best combine our various data sources, do some preliminary data quality checks and fix up the data some more where needed, and finally output the results locally. Once we're happy with the pipeline, we'll extract the code into the etl.py file that will eventually contain the whole pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run clean.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started ETL pipeline\n",
      "Started loading Covid-19 case data\n",
      "Finished loading Covid-19 case data\n",
      "Started loading Covid-19 death data\n",
      "Finished loading Covid-19 death data\n",
      "Started loading county health data\n",
      "Finished loading county health data\n",
      "Started creating time dimension table\n",
      "Started loading Covid-19 case data\n",
      "Finished loading Covid-19 case data\n",
      "Finished creating time dimension table\n",
      "Started creating county dimension table\n",
      "Started loading county area data\n",
      "Finished loading county area data\n",
      "Finished creating county dimension table\n",
      "Started creating state dimension table\n",
      "Finished creating state dimension table\n",
      "Started creating county facts table\n",
      "Started creating Covid-19 time series data for 'covid_case_total' and 'covid_case_delta'\n",
      "Finished creating Covid-19 time series data for 'covid_case_total' and 'covid_case_delta'\n",
      "Started creating Covid-19 time series data for 'covid_death_total' and 'covid_death_delta'\n",
      "Finished creating Covid-19 time series data for 'covid_death_total' and 'covid_death_delta'\n",
      "Started loading county weather data\n",
      "Finished loading county weather data\n",
      "Started creating weather time series data for 'min_temp'\n",
      "Finished creating weather time series data for 'min_temp'\n",
      "Started creating weather time series data for 'max_temp'\n",
      "Finished creating weather time series data for 'max_temp'\n",
      "Started creating weather time series data for 'cloud_cover'\n",
      "Finished creating weather time series data for 'cloud_cover'\n",
      "Started creating weather time series data for 'wind'\n",
      "Finished creating weather time series data for 'wind'\n",
      "Finished creating county facts table\n",
      "Started creating state facts table\n",
      "Finished creating state facts table\n",
      "Finished ETL pipeline\n"
     ]
    }
   ],
   "source": [
    "%run etl.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "branch-env",
   "language": "python",
   "name": "branch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
