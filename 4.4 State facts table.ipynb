{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Create the state facts table\n",
    "- Load county facts table\n",
    "- Discard weather data\n",
    "- Group by state and timestamp\n",
    "- Add up case/death total/delta\n",
    "- Write out to parquet partitioned by date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup\n",
    "I'm going to need Spark for this because I'll want to make use of some of its functionality, such as the ability to create temporary SQL views of my dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import create_spark_session\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and output paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from clean import *\n",
    "from etl import *\n",
    "\n",
    "# For now, just locally, later on maybe write this to S3 instead\n",
    "output_path = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_facts_df = load_county_facts_table(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------------+----------------+-----------------+-----------------+--------+--------+-----------+----+----------+\n",
      "|fips|     state|covid_case_total|covid_case_delta|covid_death_total|covid_death_delta|min_temp|max_temp|cloud_cover|wind| timestamp|\n",
      "+----+----------+----------------+----------------+-----------------+-----------------+--------+--------+-----------+----+----------+\n",
      "|1055|   Alabama|            6005|             100|               64|                0|    1.18|   15.19|       17.0|2.93|1606176000|\n",
      "|1097|   Alabama|           19446|             140|              360|                2|    3.75|   20.04|       17.0|3.29|1606176000|\n",
      "|5111|  Arkansas|            1602|              12|               39|                0|    2.77|   13.97|       20.0|1.41|1606176000|\n",
      "|6079|California|            5885|              74|               35|                0|    6.09|   15.35|       12.0|2.19|1606176000|\n",
      "|8059|  Colorado|           18369|             368|              425|                9|    -3.2|   13.77|       22.0|3.99|1606176000|\n",
      "+----+----------+----------------+----------------+-----------------+-----------------+--------+--------+-----------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "county_facts_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------+----------------+-----------------+-----------------+\n",
      "|     state| timestamp|covid_case_total|covid_case_delta|covid_death_total|covid_death_delta|\n",
      "+----------+----------+----------------+----------------+-----------------+-----------------+\n",
      "|   Alabama|1606176000|            6005|             100|               64|                0|\n",
      "|   Alabama|1606176000|           19446|             140|              360|                2|\n",
      "|  Arkansas|1606176000|            1602|              12|               39|                0|\n",
      "|California|1606176000|            5885|              74|               35|                0|\n",
      "|  Colorado|1606176000|           18369|             368|              425|                9|\n",
      "+----------+----------+----------------+----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "county_facts_df_reduced = county_facts_df[['state', 'timestamp', 'covid_case_total', 'covid_case_delta', 'covid_death_total', 'covid_death_delta']]\n",
    "county_facts_df_reduced.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_facts_df = county_facts_df_reduced.groupBy('state', 'timestamp').agg( \\\n",
    "    F.sum('covid_case_total').alias('covid_case_total'), \\\n",
    "    F.sum('covid_case_delta').alias('covid_case_delta'), \\\n",
    "    F.sum('covid_death_total').alias('covid_death_total'), \\\n",
    "    F.sum('covid_death_delta').alias('covid_death_delta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------------+----------------+-----------------+-----------------+\n",
      "|    state| timestamp|covid_case_total|covid_case_delta|covid_death_total|covid_death_delta|\n",
      "+---------+----------+----------------+----------------+-----------------+-----------------+\n",
      "|Tennessee|1600905600|          181808|             882|             2281|               37|\n",
      "|    Texas|1608768000|         1661626|            9138|            26868|              288|\n",
      "| Michigan|1602288000|          143360|            1600|             7137|               19|\n",
      "|   Oregon|1601683200|           34511|             348|              571|                8|\n",
      "|    Texas|1601337600|          774438|            6448|            16179|               87|\n",
      "+---------+----------+----------------+----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_facts_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_facts_df.write.partitionBy('timestamp').mode('append').parquet(output_path + \"state_facts.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
