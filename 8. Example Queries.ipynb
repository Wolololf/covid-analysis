{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Example queries\n",
    "\n",
    "What use is a data engineering project without actually asking some questions about our data? Below are some example queries (run against the local parquet files since I don't want to pay for S3 read costs).\n",
    "\n",
    "##### Setup, imports and database loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import create_spark_session\n",
    "\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from sql.exampleQueries import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started loading database\n",
      "Started loading time dimension table\n",
      "Finished loading time dimension table\n",
      "Started loading county dimension table\n",
      "Finished loading county dimension table\n",
      "Started loading state dimension table\n",
      "Finished loading state dimension table\n",
      "Started loading county facts table\n",
      "Finished loading county facts table\n",
      "Started loading state facts table\n",
      "Finished loading state facts table\n",
      "Finished loading database\n"
     ]
    }
   ],
   "source": [
    "from etl import load_all_tables\n",
    "\n",
    "time_dim_df, county_dim_df, state_dim_df, county_facts_df, state_facts_df = load_all_tables(spark)\n",
    "\n",
    "time_dim_df.createOrReplaceTempView(\"dim_time\")\n",
    "county_dim_df.createOrReplaceTempView(\"dim_county\")\n",
    "state_dim_df.createOrReplaceTempView(\"dim_state\")\n",
    "county_facts_df.createOrReplaceTempView(\"fact_county\")\n",
    "state_facts_df.createOrReplaceTempView(\"fact_state\")\n",
    "\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Queries\n",
    "Let's start simply. Which counties have the highest case rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+----------------+\n",
      "| fips|   county_name|covid_case_total|\n",
      "+-----+--------------+----------------+\n",
      "| 6037|   Los Angeles|         1190894|\n",
      "| 4013|      Maricopa|          509683|\n",
      "|17031|          Cook|          473944|\n",
      "|12086|    Miami-Dade|          409216|\n",
      "|48201|        Harris|          348848|\n",
      "| 6065|     Riverside|          289450|\n",
      "| 6071|San Bernardino|          286291|\n",
      "|48113|        Dallas|          280404|\n",
      "| 6059|        Orange|          261022|\n",
      "| 6073|     San Diego|          259641|\n",
      "+-----+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT fc.fips, dc.county_name, max(fc.covid_case_total) as covid_case_total\n",
    "        FROM fact_county fc\n",
    "        LEFT JOIN dim_county dc\n",
    "        ON fc.fips == dc.fips\n",
    "        GROUP BY fc.fips, dc.county_name\n",
    "        ORDER BY covid_case_total DESC\n",
    "        LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which states have the most deaths in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|         state|covid_case_total|\n",
      "+--------------+----------------+\n",
      "|    California|         3563578|\n",
      "|         Texas|         2649363|\n",
      "|       Florida|         1900218|\n",
      "|      New York|         1635820|\n",
      "|      Illinois|         1185363|\n",
      "|       Georgia|          971325|\n",
      "|          Ohio|          966154|\n",
      "|  Pennsylvania|          931531|\n",
      "|North Carolina|          858547|\n",
      "|       Arizona|          815705|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT fs.state, max(fs.covid_case_total) as covid_case_total\n",
    "        FROM fact_state fs\n",
    "        GROUP BY fs.state\n",
    "        ORDER BY covid_case_total DESC\n",
    "        LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these are a bit misleading, though. Counties with higher population numbers are bound to have higher rates, so let's run these queries again but normalise them to the county/state population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+-------------------+\n",
      "| fips|  county_name|    norm_case_total|\n",
      "+-----+-------------+-------------------+\n",
      "| 8025|      Crowley|0.33817002389894163|\n",
      "|13053|Chattahoochee| 0.2878135529764133|\n",
      "| 8011|         Bent| 0.2512750765045903|\n",
      "|46041|        Dewey|0.23899051490514905|\n",
      "|19021|  Buena Vista|0.23784844520479018|\n",
      "| 5079|      Lincoln| 0.2358215646715983|\n",
      "|47095|         Lake| 0.2264201862096883|\n",
      "|20137|       Norton|0.22117863720073666|\n",
      "|47169|    Trousdale| 0.2167635306937886|\n",
      "|46009|    Bon Homme| 0.2154727793696275|\n",
      "+-----+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    WITH county_norm AS (\n",
    "        SELECT fc.fips, fc.covid_case_total / dc.population as norm_case_total\n",
    "        FROM fact_county fc\n",
    "        LEFT JOIN dim_county dc\n",
    "        ON fc.fips == dc.fips\n",
    "        GROUP BY fc.fips, fc.covid_case_total, dc.population\n",
    "    )\n",
    "    SELECT fc.fips, dc.county_name, dc.state, max(cn.norm_case_total) as norm_case_total\n",
    "        FROM fact_county fc\n",
    "        LEFT JOIN dim_county dc\n",
    "        ON fc.fips == dc.fips\n",
    "        LEFT JOIN county_norm cn\n",
    "        ON fc.fips == cn.fips\n",
    "        GROUP BY fc.fips, dc.county_name, dc.state\n",
    "        ORDER BY norm_case_total DESC\n",
    "        LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+----------+\n",
      "|               state|covid_death_total|population|\n",
      "+--------------------+-----------------+----------+\n",
      "|District of Columbia|              578|      null|\n",
      "|       Massachusetts|             8288|      null|\n",
      "|             Indiana|              116|      null|\n",
      "|        North Dakota|             1352|      null|\n",
      "|        South Dakota|               65|      null|\n",
      "|        Rhode Island|             2220|      null|\n",
      "|        South Dakota|             1110|      null|\n",
      "|        Pennsylvania|             9005|      null|\n",
      "|        Pennsylvania|             4417|      null|\n",
      "|        North Dakota|              246|      null|\n",
      "+--------------------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT fs.state, fs.covid_death_total, ds.population\n",
    "    FROM fact_state fs\n",
    "    LEFT JOIN dim_state ds\n",
    "    ON fs.state == ds.state\n",
    "    GROUP BY fs.state, fs.covid_death_total, ds.population\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|               state|norm_death_total|\n",
      "+--------------------+----------------+\n",
      "|District of Columbia|            null|\n",
      "|       Massachusetts|            null|\n",
      "|             Indiana|            null|\n",
      "|        North Dakota|            null|\n",
      "|        South Dakota|            null|\n",
      "|        Rhode Island|            null|\n",
      "|        South Dakota|            null|\n",
      "|        Pennsylvania|            null|\n",
      "|        Pennsylvania|            null|\n",
      "|        North Dakota|            null|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT fs.state, fs.covid_death_total / ds.population as norm_death_total\n",
    "    FROM fact_state fs\n",
    "    LEFT JOIN dim_state ds\n",
    "    ON fs.state == ds.state\n",
    "    GROUP BY fs.state, fs.covid_death_total, ds.population\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|       state|norm_death_total|\n",
      "+------------+----------------+\n",
      "|        Utah|            null|\n",
      "|      Hawaii|            null|\n",
      "|   Minnesota|            null|\n",
      "|        Ohio|            null|\n",
      "|    Arkansas|            null|\n",
      "|      Oregon|            null|\n",
      "|       Texas|            null|\n",
      "|North Dakota|            null|\n",
      "|Pennsylvania|            null|\n",
      "| Connecticut|            null|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    WITH state_norm AS (\n",
    "        SELECT fs.state, fs.covid_death_total / ds.population as norm_death_total\n",
    "        FROM fact_state fs\n",
    "        LEFT JOIN dim_state ds\n",
    "        ON fs.state == ds.state\n",
    "        GROUP BY fs.state, fs.covid_death_total, ds.population\n",
    "    )\n",
    "    SELECT fs.state, max(sn.norm_death_total) as norm_death_total\n",
    "        FROM fact_state fs\n",
    "        LEFT JOIN state_norm sn\n",
    "        ON fs.state == sn.state\n",
    "        GROUP BY fs.state\n",
    "        ORDER BY norm_death_total DESC\n",
    "        LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for something a bit more tricky: Which counties have the largest temperature swings during the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT fc.fips, dc.county_name, fc.max_temp - fc.min_temp as temp_change\n",
    "        FROM fact_county fc\n",
    "        LEFT JOIN dim_county dc\n",
    "        ON fc.fips == dc.fips\n",
    "        GROUP BY fc.fips, dc.county_name\n",
    "        ORDER BY covid_case_total DESC\n",
    "        LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd like to know how strongly Covid case rates correlate to population density. My guess is that high population density results in higher infection rates. To check this, we'll need to get the total case count for each county and normalise it for the total population, then compare the various percentiles of population density in the data set. We could split the whole dataset into 10% buckets of population density and calculate the average normalised case rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also curious about how strongly a county's average temperature correlates with case rates. I'd assume that warmer counties fare worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A harder question to answer is how much weather on any given day affects covid case rates a few days down the line.  \n",
    "Since the reporting won't be extremely accurate, we should limit ourselves to evaluating strings of consistently good/bad weather for a few days, and then look at the new case increase a week afterwards.\n",
    "\n",
    "First, we need to classify what makes a day \"good\" or \"bad\". I'd define a \"good\" day as having low chance of precipitation and low cloud cover, whereas a \"bad\" day is high on both. We could include temperature here as well, but we'd need to look at a rolling average to see how any given day compares; this presents a problem since rolling averages don't play well with the idea of having a period of good/bad days (they're subsequent days, so the last day in the sequence would need e.g. a higher temperature than the preceding days even though they were classed as \"good\" already).\n",
    "\n",
    "Next, we need to indentify sufficiently long sequences of days with similar weather.  \n",
    "Then we can determine the cases a week from each day, and track the delta.\n",
    "\n",
    "Finally, we can average the delta for good/bad weather days and see if we can find any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "branch-env",
   "language": "python",
   "name": "branch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
